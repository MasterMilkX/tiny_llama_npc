{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f15cd9",
   "metadata": {},
   "source": [
    "# Finetune Tiny Llama for NPC TT Experiment\n",
    "Vibe coded with ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8cd7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b36cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 201/201 [00:38<00:00,  5.25it/s, Materializing param=model.norm.weight]                              \n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "BASE_MODEL_ID = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95bed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b4605",
   "metadata": {},
   "source": [
    "## Instructions to train the model\n",
    "1. Create a dataset of based on current interactions in the game in JSON format showing the current avatar's name, position, and game map location. Include a JSON list of player data for all players on the screen that includes their name, position, and text (emote) if they're talking. For the output, use a JSON object action with the choices [text, emote, move]\n",
    "2. Create sets for each role and how they should respond to situations augmenting with artificial data made combining Jae's JSON and ChatGPT output in the format specified\n",
    "3. Finetune TinyLlama on the fake outputs\n",
    "4. Connect to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4fc9e",
   "metadata": {},
   "source": [
    "ChatGPT prompt format:\n",
    "\n",
    "```\n",
    "Can you make a dataset of custom responses for an avatar NPC based on a particular role? I need 100 samples of interactions and responses between an NPC and another character. The possible input interactions will be either text or an emote from the emote.txt file. You can use the role_dialog.json file for examples of keyword outputs or generic lines too. For example, the input interaction should be formatted like such {\"text\": \"Hi, I'd like some bread\"} or {\"emote\":\"004-big-smile\"}. The output interaction should be formatted similarly like \"{\"text\": \"Sure, it's fresh baked!\"}\" or {\"emote\":\"020-money-bag\"} for the baker NPC role. Each interaction should be separated by a new line like such:\n",
    "\n",
    "    INPUT: {\"text\": \"Hi, I'd like some bread\"}\n",
    "    OUTPUT: {\"emote\":\"020-money-bag\"}\n",
    "\n",
    "Can you make 100 samples for the {INSERT ROLE HERE} role using a mix of text and emote inputs and outputs? \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b01a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_INSTRUCTIONS = {}\n",
    "with open(\"train-data/role_instructions.json\", \"r\") as f:\n",
    "    jdat = json.load(f)\n",
    "    for role, instr in jdat.items():\n",
    "        ROLE_INSTRUCTIONS[role] = {}\n",
    "        ROLE_INSTRUCTIONS[role]['descr'] = instr['description']\n",
    "        ROLE_INSTRUCTIONS[role]['tasks'] = [t for t in instr['tasks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_INSTRUCTIONS = lambda npc_role: (\"Pretend you are human player role-playing as an NPC character with a job in a medieval fantasy world. \"\n",
    "    f\"Your job is a '{npc_role.upper()}' character. \"\n",
    "    f\"These are the {npc_role.upper()} character instructions: \"\n",
    "    f\"{ROLE_INSTRUCTIONS[npc_role]['descr']} \"\n",
    "    f\"The {npc_role.upper()} role's tasks are: {', '.join(ROLE_INSTRUCTIONS[npc_role]['tasks'])}. \"\n",
    "    \"You can either talk to another player or perform an action. \"\n",
    "    \"You have the following actions available: [talk, move, emote, teleport]. \"\n",
    "    \"If you want to talk, respond in normal text in the following form {'talk': '(your message)'}. For example, {'talk': 'Hello there!'}. \"\n",
    "    \"You can only respond in one sentence with a maximum of 100 characters for the text. \"\n",
    "    \"For emotes, you have the following icon choices available: [wave, dance, happy,big,laugh,intelligent,sleeping,bored,surprise,frightened,cry,angry,numb,sweat,tongue,numb,kissing,heart,star,star,like,close,help,daisy,gift,money,axe,chicken,tomato,mushroom,chemical,beer]. \"\n",
    "    \"If you want to emote, respond in the following form {'emote': '(your emote choice)'}. For example, {'emote': 'wave'}. \"\n",
    "    \"For movements, you can move to any (x,y) coordinate in the range of (0,0) to (800,400). \"\n",
    "    \"If you want to move, respond in the following form {'move': '(x,y)'}. For example, {'move': '30,100'}. \"\n",
    "    \"For teleportation, you can teleport to the following locations: ['plaza','library','blacksmith','training_ground','bakery','butcher','market','apothecary','tavern']. \"\n",
    "    \"If you want to teleport, respond in the following form {'teleport': '(location)'}. For example, {'teleport': 'plaza'}. \"\n",
    "    \"Only give your response in one of these four forms as a JSON format with the action chosen and the value. For example: {'talk': 'Hello there!'} or {'move': '30,100'}. \"\n",
    "    f\"Try to stay in character as a '{npc_role.upper()}' and respond appropriately based on your role and the context of the interaction. \"\n",
    "    \"Respond often with text or emotes, and only move or teleport when necessary. \"\n",
    "    \"\\n\")\n",
    "\n",
    "\n",
    "ALL_LOCS = ['plaza','library','blacksmith','training_ground','bakery','butcher','market','apothecary','tavern']\n",
    "ALL_ROLES = ['blacksmith','baker','bard','chuck','butcher','apothecary','knight_trainer','librarian','general_goods','drunk','gossip','mercenary','barmaid','wizard']\n",
    "ROLE_LOCS = {\n",
    "    'blacksmith': 'blacksmith',\n",
    "    'baker': 'bakery',\n",
    "    'bard': 'tavern',\n",
    "    'chuck': 'tavern',\n",
    "    'butcher': 'butcher',\n",
    "    'apothecary': 'apothecary',\n",
    "    'knight_trainer': 'training_ground',\n",
    "    'librarian': 'library',\n",
    "    'general_goods': 'market',\n",
    "    'drunk': 'tavern',\n",
    "    'gossip': 'tavern',\n",
    "    'mercenary': 'training_ground',\n",
    "    'barmaid': 'tavern',\n",
    "    'wizard': 'apothecary'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06452227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FULL TRAINING DATA\n",
    "def self_avatar_data(role, loc):\n",
    "    LETTERS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    name = ' '.join(random.choices(LETTERS, k=2))\n",
    "    position = (random.randint(0,800), random.randint(0,400))\n",
    "    avatar = {\n",
    "        \"name\": name,\n",
    "        \"pos\": position,\n",
    "        \"role\": role,\n",
    "        \"loc\": loc\n",
    "    }\n",
    "    return avatar\n",
    "\n",
    "def rand_avatar_data(text=None,emote=None):\n",
    "    LETTERS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    name = ' '.join(random.choices(LETTERS, k=2))\n",
    "    position = (random.randint(0,800), random.randint(0,400))\n",
    "    avatar = {\n",
    "        \"name\": name,\n",
    "        \"pos\": position,\n",
    "    }\n",
    "    if text:\n",
    "        avatar[\"text\"] = text\n",
    "    if emote:\n",
    "        avatar[\"emote\"] = emote\n",
    "    return avatar\n",
    "\n",
    "\n",
    "def read_inter_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # data is defined with the following format:\n",
    "    '''\n",
    "        INPUT: {}\n",
    "        OUTPUT: {}\n",
    "\n",
    "        INPUT: {}\n",
    "        OUTPUT: {}\n",
    "        ...\n",
    "    '''\n",
    "    data = data.split(\"\\n\\n\")\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        if entry.strip() == \"\":\n",
    "            continue\n",
    "        input_part, output_part = entry.split(\"OUTPUT:\")\n",
    "        input_json = input_part.replace(\"INPUT:\", \"\").strip()\n",
    "        output_json = output_part.strip()\n",
    "        processed_data.append((input_json, output_json))\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bba86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating training data: 100%|██████████| 14/14 [00:00<00:00, 47.05it/s, role=wizard, lines=82/82]       \n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATASET FOR TRAINING\n",
    "\n",
    "def generate_training_data():\n",
    "    dataset = []\n",
    "\n",
    "    l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "    emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "\n",
    "    # shuffle l33t and emote data\n",
    "    random.shuffle(l33t_data)\n",
    "    random.shuffle(emote_data)\n",
    "\n",
    "    with tqdm(total=len(ALL_ROLES), desc=\"Generating training data\") as pbar:\n",
    "        for role in ALL_ROLES:\n",
    "            # read in the role specific data\n",
    "            role_data = read_inter_data(f'train-data/{role}_inter.txt')\n",
    "\n",
    "            # shuffle role data\n",
    "            random.shuffle(role_data)\n",
    "\n",
    "            d = 0\n",
    "            for dat in role_data:\n",
    "                d += 1\n",
    "                pbar.set_postfix({\"role\": role, \"lines\":f\"{d}/{len(role_data)}\"})\n",
    "\n",
    "                # create self avatar data\n",
    "                loc = random.choices(ALL_LOCS, weights=[0.25 if l == \"plaza\" else 0.1 if l != ROLE_LOCS[role] else 0.4 for l in ALL_LOCS])[0]\n",
    "                self_avatar = self_avatar_data(role, loc)\n",
    "\n",
    "                # create other avatars data\n",
    "                num_others = random.randint(1,5)\n",
    "                other_avatars = []\n",
    "\n",
    "                # add input line from role data as one of the other avatars\n",
    "                other_input = json.loads(dat[0])\n",
    "                reaction = json.loads(dat[1])\n",
    "                rand_avatar = rand_avatar_data(text=other_input.get(\"text\",None), emote=other_input.get(\"emote\",None))\n",
    "                other_avatars.append(rand_avatar)\n",
    "\n",
    "                # add additional other avatars\n",
    "                for _ in range(num_others-1):\n",
    "\n",
    "                    # if we run out of l33t or emote data, refill\n",
    "                    if len(l33t_data) == 0:\n",
    "                        l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "                        random.shuffle(l33t_data)\n",
    "                    if len(emote_data) == 0:\n",
    "                        emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "                        random.shuffle(emote_data)\n",
    "\n",
    "\n",
    "                    # randomly choose to add l33t, emote data, or nothing\n",
    "                    s = random.random()\n",
    "                    if s < 0.3:\n",
    "                        dat = json.loads(l33t_data.pop()[0])\n",
    "                    elif s < 0.6:\n",
    "                        dat = json.loads(emote_data.pop()[0])\n",
    "\n",
    "                    # create another random avatar\n",
    "                    txt = None\n",
    "                    emote = None\n",
    "                    if \"text\" in dat:\n",
    "                        txt = dat[\"text\"]\n",
    "                    if \"emote\" in dat:\n",
    "                        emote = dat[\"emote\"]\n",
    "\n",
    "                    another_avatar = rand_avatar_data(text=txt, emote=emote)\n",
    "                    other_avatars.append(another_avatar)\n",
    "\n",
    "                # shuffle other avatars\n",
    "                random.shuffle(other_avatars)\n",
    "\n",
    "                # create the input-output pair\n",
    "                input_data = {\n",
    "                    \"ME\": self_avatar,\n",
    "                    \"OTHER\": other_avatars\n",
    "                }\n",
    "                dataset.append({\n",
    "                    \"input\": input_data,\n",
    "                    \"output\": reaction\n",
    "                })\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "    emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "\n",
    "    comb = l33t_data + emote_data\n",
    "    random.shuffle(comb)\n",
    "\n",
    "    # adds the leet and emote data at the end to ensure they are all used\n",
    "    for dat in comb:\n",
    "\n",
    "        # 1. direct response, 2. move, 3. teleport\n",
    "        for i in range(3):\n",
    "\n",
    "            # create self avatar data\n",
    "            role = random.choices(ALL_ROLES)[0]\n",
    "            loc = random.choices(ALL_LOCS, weights=[0.25 if l == \"plaza\" else 0.1 if l != ROLE_LOCS[role] else 0.4 for l in ALL_LOCS])[0]\n",
    "            self_avatar = self_avatar_data(role, loc)\n",
    "\n",
    "            # create other avatars data\n",
    "            num_others = random.randint(1,5)\n",
    "            other_avatars = []\n",
    "\n",
    "            # add input line from role data as one of the other avatars\n",
    "            other_input = json.loads(dat[0])\n",
    "            reaction = json.loads(dat[1])\n",
    "            rand_avatar = rand_avatar_data(text=other_input.get(\"text\",None), emote=other_input.get(\"emote\",None))\n",
    "            other_avatars.append(rand_avatar)\n",
    "\n",
    "            # add additional other avatars\n",
    "            for _ in range(num_others-1):\n",
    "                another_avatar = rand_avatar_data()\n",
    "                other_avatars.append(another_avatar)\n",
    "\n",
    "            # shuffle other avatars\n",
    "            random.shuffle(other_avatars)\n",
    "\n",
    "            # create the input-output pair\n",
    "            input_data = {\n",
    "                \"ME\": self_avatar,\n",
    "                \"OTHER\": other_avatars\n",
    "            }\n",
    "\n",
    "            # set reaction based on i\n",
    "            if i == 1:\n",
    "                # move\n",
    "                reaction = {\n",
    "                    \"move\": f\"{random.randint(0,800)},{random.randint(0,400)}\"\n",
    "                }\n",
    "            elif i == 2:\n",
    "                # teleport\n",
    "                reaction = {\n",
    "                    \"teleport\": random.choice(ALL_LOCS)\n",
    "                }\n",
    "\n",
    "            dataset.append({\n",
    "                \"input\": input_data,\n",
    "                \"output\": reaction\n",
    "            })\n",
    "\n",
    "    with open('train-data/npc_training_data.json', 'w') as f:\n",
    "        json.dump(dataset, f)\n",
    "\n",
    "generate_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the JSON list to have each element on a single line with indentation only at the list level\n",
    "def format_list_shallow(json_path, out_path):\n",
    "    # Load the raw JSON list\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    lines = [\"[\"]\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        # Dump each element on a single line (minified)\n",
    "        minified = json.dumps(item, separators=(\",\", \":\"))\n",
    "\n",
    "        # Indent only at the list level\n",
    "        if i < len(data) - 1:\n",
    "            lines.append(f\"  {minified},\")\n",
    "        else:\n",
    "            lines.append(f\"  {minified}\")\n",
    "\n",
    "    lines.append(\"]\")\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "format_list_shallow(\"train-data/npc_training_data.json\", \"train-data/npc_training_data_pretty.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b19ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    dataset = []\n",
    "    for item in data:\n",
    "        input_data = item['input']\n",
    "        output_data = item['output']\n",
    "        dataset.append({\n",
    "            \"messages\":[\n",
    "                {\"role\": \"system\", \"content\": FULL_INSTRUCTIONS(input_data[\"ME\"][\"role\"])},\n",
    "                {\"role\": \"user\", \"content\": input_data},\n",
    "                {\"role\": \"assistant\", \"content\": output_data}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    # export to .jsonl file\n",
    "    with open('npc_dataset.jsonl', 'w') as f:\n",
    "        for entry in dataset:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_raw_dataset(path: str) -> Dataset:\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            fixed_messages = []\n",
    "            for m in obj[\"messages\"]:\n",
    "                role = m[\"role\"]\n",
    "                content = m[\"content\"]\n",
    "\n",
    "                # Normalize: ensure content is always a dict\n",
    "                if isinstance(content, str):\n",
    "                    # Wrap string in {\"text\": ...}\n",
    "                    content = {\"text\": content}\n",
    "\n",
    "                fixed_messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "            data.append({\"messages\": fixed_messages})\n",
    "\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d1dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \"\"\"\n",
    "    Convert one example {\"messages\": [...]} into a single training string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for msg in example[\"messages\"]:\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "\n",
    "        # If it has only \"text\", show just the text\n",
    "        if isinstance(content, dict) and set(content.keys()) == {\"text\"}:\n",
    "            text = content[\"text\"]\n",
    "        else:\n",
    "            # For structured ME/OTHER etc, dump as JSON string\n",
    "            text = json.dumps(content, ensure_ascii=False)\n",
    "\n",
    "        parts.append(f\"[{role}]\\n{text}\")\n",
    "\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ed621",
   "metadata": {},
   "source": [
    "## Alt Formatting for Finetuning\n",
    "Because either SFT or ChatGPT shat itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c72e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_to_text(messages):\n",
    "    \"\"\"\n",
    "    Turn one example's messages list into a single training string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "\n",
    "        # content can be a string or an object (ME/OTHER or {\"text\": ...})\n",
    "        if isinstance(content, str):\n",
    "            text = content\n",
    "        elif isinstance(content, dict) and set(content.keys()) == {\"text\"}:\n",
    "            text = content[\"text\"]\n",
    "        else:\n",
    "            # For structured stuff (ME/OTHER etc.), serialize to JSON\n",
    "            text = json.dumps(content, ensure_ascii=False)\n",
    "\n",
    "        parts.append(f\"[{role}]\\n{text}\")\n",
    "\n",
    "    # You could also mark where the assistant answer starts specially if you want\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "def build_text_dataset(jsonl_path: str) -> Dataset:\n",
    "    \"\"\"\n",
    "    Read npc_dataset.jsonl, normalize everything, and create a Dataset\n",
    "    with a single 'text' column (no 'messages' column at all).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            messages = obj[\"messages\"]\n",
    "\n",
    "            # Normalize content: if it's a string, wrap into {\"text\": ...}\n",
    "            norm_msgs = []\n",
    "            for m in messages:\n",
    "                role = m[\"role\"]\n",
    "                content = m[\"content\"]\n",
    "                if isinstance(content, str):\n",
    "                    content = {\"text\": content}\n",
    "                norm_msgs.append({\"role\": role, \"content\": content})\n",
    "\n",
    "            text = messages_to_text(norm_msgs)\n",
    "            rows.append({\"text\": text})\n",
    "\n",
    "    with open('npc_dataset_text.jsonl', 'w') as f:\n",
    "        for row in rows:\n",
    "            f.write(json.dumps(row) + '\\n')\n",
    "\n",
    "    return Dataset.from_list(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360a2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 2064\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_text_dataset(\"train-data/npc_dataset.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5dfcda",
   "metadata": {},
   "source": [
    "## Train the model with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding-free training is enabled, but the attention implementation is not set to a supported flash attention variant. Padding-free training flattens batches into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation` in the model configuration to one of these supported options or verify that your attention mechanism can handle flattened sequences.\n",
      "You are using packing, but the attention implementation is not set to a supported flash attention variant. Packing gathers multiple samples into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to cross-contamination between samples. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation` in the model configuration to one of these supported options.\n",
      "Adding EOS to train dataset: 100%|██████████| 2064/2064 [00:00<00:00, 49078.71 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 2064/2064 [00:00<00:00, 2307.13 examples/s]\n",
      "Packing train dataset: 100%|██████████| 2064/2064 [00:00<00:00, 30730.34 examples/s]\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n",
      "/Users/mcharit2/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     96\u001b[39m     tokenizer.save_pretrained(MERGED_OUTPUT_DIR)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved merged full model to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMERGED_OUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mfinetune\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 73\u001b[39m, in \u001b[36mfinetune\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     62\u001b[39m  trainer = SFTTrainer(\n\u001b[32m     63\u001b[39m      model=model,\n\u001b[32m     64\u001b[39m      args=sft_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m      \u001b[38;5;66;03m# formatting_func=formatting_func,  # takes raw example -> string\u001b[39;00m\n\u001b[32m     69\u001b[39m  )\n\u001b[32m     72\u001b[39m  \u001b[38;5;66;03m# 6) Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m  \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# 7) Save LoRA adapter + tokenizer locally\u001b[39;00m\n\u001b[32m     76\u001b[39m  os.makedirs(LORA_OUTPUT_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/trainer.py:2164\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2162\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2163\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2165\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/trainer.py:2527\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2520\u001b[39m context = (\n\u001b[32m   2521\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2522\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2523\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2524\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2525\u001b[39m )\n\u001b[32m   2526\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2527\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2530\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2531\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2532\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2533\u001b[39m ):\n\u001b[32m   2534\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2535\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/trl/trainer/sft_trainer.py:1190\u001b[39m, in \u001b[36mSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/trainer.py:3813\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3810\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3812\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3813\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3815\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3818\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3819\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/trl/trainer/sft_trainer.py:1103\u001b[39m, in \u001b[36mSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;66;03m# If not set, defaults from model config and may warn since cache isn't compatible with gradient checkpointing\u001b[39;00m\n\u001b[32m   1102\u001b[39m inputs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m (loss, outputs) = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;66;03m# Compute entropy\u001b[39;00m\n\u001b[32m   1108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_liger_kernel:  \u001b[38;5;66;03m# liger doesn't return logits\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/trainer.py:3884\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3882\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3883\u001b[39m     inputs = {**inputs, **kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;66;03m# User-defined compute_loss function\u001b[39;00m\n\u001b[32m   3887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/peft/peft_model.py:1923\u001b[39m, in \u001b[36mPeftModelForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[39m\n\u001b[32m   1921\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(**kwargs):\n\u001b[32m   1922\u001b[39m         kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1924\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1927\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1928\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1929\u001b[39m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1930\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1931\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1932\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1934\u001b[39m batch_size = _get_batch_size(input_ids, inputs_embeds)\n\u001b[32m   1935\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1936\u001b[39m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/peft/tuners/tuners_utils.py:308\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/utils/generic.py:768\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    767\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    770\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/models/llama/modeling_llama.py:487\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    468\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    469\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    470\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    471\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    472\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    485\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    499\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/utils/generic.py:938\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    936\u001b[39m             outputs = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m    940\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m    942\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m    943\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/models/llama/modeling_llama.py:422\u001b[39m, in \u001b[36mLlamaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[39m\n\u001b[32m    419\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids=position_ids)\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    435\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    436\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    437\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         message = message.rstrip(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_gradient_checkpointing_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/_dynamo/eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/utils/checkpoint.py:496\u001b[39m, in \u001b[36mcheckpoint\u001b[39m\u001b[34m(function, use_reentrant, context_fn, determinism_check, debug, early_stop, *args, **kwargs)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    492\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    493\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muse_reentrant=False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    498\u001b[39m     gen = _checkpoint_without_reentrant_generator(\n\u001b[32m    499\u001b[39m         function, preserve, context_fn, determinism_check, debug, early_stop, *args, **kwargs\n\u001b[32m    500\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/autograd/function.py:581\u001b[39m, in \u001b[36mFunction.apply\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch._C._are_functorch_transforms_active():\n\u001b[32m    579\u001b[39m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[32m    580\u001b[39m     args = _functorch.utils.unwrap_dead_wrappers(args)\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[32m    584\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstaticmethod. For more details, please see \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    589\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/utils/checkpoint.py:262\u001b[39m, in \u001b[36mCheckpointFunction.forward\u001b[39m\u001b[34m(ctx, run_function, preserve_rng_state, *args)\u001b[39m\n\u001b[32m    259\u001b[39m ctx.save_for_backward(*tensor_inputs)\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     outputs = \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/models/llama/modeling_llama.py:336\u001b[39m, in \u001b[36mLlamaDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    334\u001b[39m residual = hidden_states\n\u001b[32m    335\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/transformers/models/llama/modeling_llama.py:184\u001b[39m, in \u001b[36mLlamaMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) * \u001b[38;5;28mself\u001b[39m.up_proj(x))\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/peft/tuners/lora/layer.py:807\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m x = \u001b[38;5;28mself\u001b[39m._cast_input_dtype(x, lora_A.weight.dtype)\n\u001b[32m    806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m active_adapter \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lora_variant:  \u001b[38;5;66;03m# vanilla LoRA\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m     result = result + lora_B(lora_A(\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)) * scaling\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.lora_variant[active_adapter].forward(\n\u001b[32m    810\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    811\u001b[39m         active_adapter=active_adapter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    815\u001b[39m         **kwargs,\n\u001b[32m    816\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/modules/dropout.py:73\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/tiny_llama_npc/tiny_llm/lib/python3.14/site-packages/torch/nn/functional.py:1418\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1418\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1419\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Output directories (all local folders)\n",
    "LORA_OUTPUT_DIR = \"./tinyllama-npc-lora\"\n",
    "MERGED_OUTPUT_DIR = \"./tinyllama-npc-merged\"\n",
    "\n",
    "MAX_SEQ_LEN = 1024\n",
    "\n",
    "DATA_FILE = \"train-data/npc_dataset.jsonl\"\n",
    "\n",
    "def finetune():\n",
    "    \n",
    "    # 3) Load raw dataset (still has 'messages')\n",
    "    #train_dataset = load_raw_dataset(DATA_FILE)\n",
    "\n",
    "    # 3) Dataset: plain text only, no messages→no chat_template\n",
    "    train_dataset = build_text_dataset(DATA_FILE)\n",
    "\n",
    "\n",
    "    # 3) LoRA configuration\n",
    "    peft_config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # 5) SFTConfig (this is where max_length, packing, lr, etc live now)\n",
    "    sft_config = SFTConfig(\n",
    "        output_dir=LORA_OUTPUT_DIR,\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=50,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\",\n",
    "        dataset_text_field=\"text\",\n",
    "\n",
    "        # sequence / packing settings\n",
    "        max_length=MAX_SEQ_LEN,   # replaces old max_seq_length\n",
    "        packing=True,            # pack examples into fixed-length sequences\n",
    "\n",
    "        # mixed precision\n",
    "        bf16=(\n",
    "            torch.cuda.is_available()\n",
    "            and torch.cuda.get_device_capability(0)[0] >= 8\n",
    "        ),\n",
    "        fp16=False,\n",
    "    )\n",
    "\n",
    "    # 6) SFTTrainer (new API for trl 0.25.1)\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=sft_config,\n",
    "        train_dataset=train_dataset,\n",
    "        processing_class=tokenizer,  # replaces tokenizer=...\n",
    "        peft_config=peft_config,\n",
    "        # formatting_func=formatting_func,  # takes raw example -> string\n",
    "    )\n",
    "\n",
    "\n",
    "    # 6) Train\n",
    "    trainer.train()\n",
    "\n",
    "   # 7) Save LoRA adapter + tokenizer locally\n",
    "    os.makedirs(LORA_OUTPUT_DIR, exist_ok=True)\n",
    "    trainer.model.save_pretrained(LORA_OUTPUT_DIR)\n",
    "    tokenizer.save_pretrained(LORA_OUTPUT_DIR)\n",
    "    print(f\"Saved LoRA adapter to {LORA_OUTPUT_DIR}\")\n",
    "\n",
    "    # 8) Merge LoRA weights into base model and save a standalone model\n",
    "    print(\"Merging LoRA adapter into base model...\")\n",
    "\n",
    "    # Reload base model on CPU (or cuda if you want)\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_ID,\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "        device_map=\"cpu\",   # merge on CPU to avoid GPU OOM\n",
    "    )\n",
    "\n",
    "    lora_model = PeftModel.from_pretrained(base_model, LORA_OUTPUT_DIR)\n",
    "    merged_model = lora_model.merge_and_unload()  # apply LoRA weights into base\n",
    "\n",
    "    os.makedirs(MERGED_OUTPUT_DIR, exist_ok=True)\n",
    "    merged_model.save_pretrained(MERGED_OUTPUT_DIR)\n",
    "    tokenizer.save_pretrained(MERGED_OUTPUT_DIR)\n",
    "    print(f\"Saved merged full model to {MERGED_OUTPUT_DIR}\")\n",
    "\n",
    "finetune()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
