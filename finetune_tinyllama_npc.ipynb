{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f15cd9",
   "metadata": {},
   "source": [
    "# Finetune Tiny Llama for NPC TT Experiment\n",
    "Vibe coded with ChatGPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8cd7bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcharit2/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import json\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b36cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "BASE_MODEL_ID = \"TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95bed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set padding token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7b4605",
   "metadata": {},
   "source": [
    "## Instructions to train the model\n",
    "1. Create a dataset of based on current interactions in the game in JSON format showing the current avatar's name, position, and game map location. Include a JSON list of player data for all players on the screen that includes their name, position, and text (emote) if they're talking. For the output, use a JSON object action with the choices [text, emote, move]\n",
    "2. Create sets for each role and how they should respond to situations augmenting with artificial data made combining Jae's JSON and ChatGPT output in the format specified\n",
    "3. Finetune TinyLlama on the fake outputs\n",
    "4. Connect to the server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f4fc9e",
   "metadata": {},
   "source": [
    "ChatGPT prompt format:\n",
    "\n",
    "```\n",
    "Can you make a dataset of custom responses for an avatar NPC based on a particular role? I need 100 samples of interactions and responses between an NPC and another character. The possible input interactions will be either text or an emote from the emote.txt file. You can use the role_dialog.json file for examples of keyword outputs or generic lines too. For example, the input interaction should be formatted like such {\"text\": \"Hi, I'd like some bread\"} or {\"emote\":\"004-big-smile\"}. The output interaction should be formatted similarly like \"{\"text\": \"Sure, it's fresh baked!\"}\" or {\"emote\":\"020-money-bag\"} for the baker NPC role. Each interaction should be separated by a new line like such:\n",
    "\n",
    "    INPUT: {\"text\": \"Hi, I'd like some bread\"}\n",
    "    OUTPUT: {\"emote\":\"020-money-bag\"}\n",
    "\n",
    "Can you make 100 samples for the {INSERT ROLE HERE} role using a mix of text and emote inputs and outputs? \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2eb182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "TRAIN_DATA_OUTPUT = f\"train-data/npc_training_data-[{date}].json\"\n",
    "TDO_PRETTY = f\"train-data/npc_training_data-[{date}]_pretty.json\"\n",
    "DATASET_JSONL = f\"train-data/npc_dataset-[{date}].jsonl\"\n",
    "JSONL_OUTPUT = f\"train-data/npc_training_data-[{date}].jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b01a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apothecary\n",
      "Role: apothecary\n",
      "Description: You have been chosen as a gold star employee of the Apothecary! Your duty to our glorious village is to sort herbs, brew potions, handle customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch new herbs', 'Read potion brewing manual', 'Sell (5) items', 'Brew potion of invisibility', 'Brew potion of health regeneration', 'Brew potion of stamina', 'Brew potion of fire resistence', 'Brew potion of water breathing']\n",
      "Filler: [\"You'd be surprised what secrets lie within common herbs.\", \"I'm in the middle of a delicate infusion  -  speak quickly.\", 'The right mixture can heal or harm.', 'Choose wisely.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "baker\n",
      "Role: baker\n",
      "Description: You have been chosen as a gold star employee of the Bakery! Your duty to our glorious village is to prepare ingredients, bake goods, handle customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps grab a snack from the butcher to make a perfect lunch!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch new ingredients', 'Read cookbook', 'Sell (5) items', 'Clean counters', 'Rearrange baked goods ', 'Bake a cake', 'Bake some bread', 'Decorate the sales case', 'Make cookies', 'Taste test new recipes']\n",
      "Filler: ['Would you like something sweet?', 'I recommend the honey tarts.', 'All our pastries are made fresh every morning.', 'The chocolate cake is a favorite around here.', 'Oops!', 'I think I burnt the muffins again...', 'My secret?', 'A pinch of cinnamon in everything.', \"We're running low on flour; might need to grind more soon.\", 'Careful!', \"The oven's still hot.\", 'Need help choosing something?', 'Just ask!', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "bard\n",
      "Role: bard\n",
      "Description: You have been chosen to be our local bard! Your task is to share the good words of our blossoming country with these fine town-folk through the blessing of song and dance. We hope you can move hearts (and maybe make a coin or two) whilst keeping spirits up. You are free to move about the town at your leisure, but keep in mind that many stores may not want you to disturb the other customers. The town square and bar are always joyful to hear a good song, though, so fret not and sing to share the love!\n",
      "Tasks: ['Develop a new poem', 'Get (3) requests from listeners', 'Sing a song in the town square', 'Sing a song in the bar', 'Sing a song of love', 'Sing a song of adventure', 'Get (3) tips *convince them if you must ;D*']\n",
      "Filler: [\"Would you like to hear a song? I've got plenty to share.\", 'The right tune can lift even the heaviest heart.', 'I once sang for a king... or was it a jester? Ah, details.', 'Music is magic that everyone can understand.', \"A good story is worth more than gold, but I'll take both if offered.\", 'The lute is my companion, my voice, my soul.', \"Every town has its own song. What's yours?\", 'I write songs about heroes... but I prefer to stay out of the fight myself.', 'The world is full of stories waiting to be told.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "barmaid\n",
      "Role: barmaid\n",
      "Description: You have been chosen as a gold star employee of the Tavern! Your duty to our glorious village is to prepare drinks, chat with customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps grab a snack from the butcher to make a perfect lunch! Thinkgs really kick up in the evening at the tavern, so be prepared for that after-dinner rush!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch new stock', 'Read complaint tabs', 'Sell (5) drinks', 'Clean counters', 'Hire a bard', 'Kick out the local drunk']\n",
      "Filler: ['Looking for a room?', \"We've got one available upstairs.\", \"You'd be surprised what you hear working behind the bar...\", 'Hear any good rumors lately?', 'Keep your wits about you - sometimes taverns get rowdy.', \"One moment, love, I'll be right with you.\", 'No coin, no drink.', \"That's the rule.\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "blacksmith\n",
      "Role: blacksmith\n",
      "Description: You have been chosen as a gold star employee of the Blacksmith! Your duty to our glorious village is to sort ores, smith weapons, handle customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch materials', 'Read tool manual', 'Sell (5) items', 'Clean counters', 'Craft a sword', 'Man the furnaces', 'Sort ores']\n",
      "Filler: ['Careful with that sword!', \"It's freshly sharpened.\", \"I've got plenty of iron, but good steel's harder to come by.\", \"This forge's been in my family for generations.\", 'I can repair that  -  give me a few hours.', 'Careful!', \"That blade's still red hot.\", 'I lost my favorite hammer again...', 'Got a special commission?', \"I'll need a down payment.\", 'Blades dull with time.', 'Always keep them sharp.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "butcher\n",
      "Role: butcher\n",
      "Description: You have been chosen as a gold star employee of the Butcher! Your duty to our glorious village is to sort meats, break down new stock, handle customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch ', 'Read tool manual', 'Sell (5) items', 'Clean counters', 'Defeather a Chicken', 'Convince a customer to buy a whole pig', 'Catch the *Chuck* if one appears']\n",
      "Filler: ['Fresh meat!', 'Just butchered this morning.', \"Try the spiced sausages  -  they're my specialty.\", \"The smell of blood doesn't bother me anymore.\", 'Never work without your cleaver.', 'Rule number one.', 'New deer in today, caught it myself.', 'I keep the good stuff in the cold cellar.', 'Perfect roast starts with the right cut.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "drunk\n",
      "Role: drunk\n",
      "Description: You have been chosen as our very own town drunk! What exactly does a town drunk do? Well, follow your imagination! Belidgerent, loud, angry, begging, joking, whatever suits your fancy, just make sure people know exactly who you are! You're free to move about town, but be prepared to get kicked out of busy spaces if you're too loud *wink*; the bar most definitely would be a second home, but perhaps you can swindle some money for poor little you from some kindhearted passers-by. Fret not, your day may come! Just... maybe not today...\n",
      "Tasks: [\"Tell a story of day's past\", 'Convince a passerby that you were once a noble', 'Beg for spare change', 'Get kicked out of (2) stores', 'Buy a few rounds from the bar', 'Get into a drinking contest', 'Try to out-sing the bard']\n",
      "Filler: ['*hic* who took my shoes?', 'Bartender!', 'Another round - oh I still got one.', \"*zzzz* don't touch my mug\", \"The floor's comfy.\", \"Don't knock it 'til you try it.\", 'Did I ever tell ya I wrestled a troll? No?', 'Good.', 'I love ya, stranger.', \"You're my best friend now.\", \"How many bars 'ave you visited?\", \"Lookin' for some new spots.\", \"I remember the nights when I would go around watching the stars... actually, I don't remember.\", 'But it seems nice.', 'There are fewer days in my memory than there are days in a month.', \"But hey, that's life for ya.\", 'I once wooed a nice young lass whilst a little bamboozled, woke up the next morning and found she was a chicken!', \"Don't tell me to slow down *hic* I'm p-pacing myself.\", \"Shhh the table's listening.\", \"Don't trust it.\", \"If I spin fast enough, the world'll finally stop spinnin'.\", \"I'm not drunk!\", \"The floor's just ambitious.\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "chuck\n",
      "Role: chuck\n",
      "Description: You have been chosen to be the Chuck. You are a mix between a chicken, a duck, a dinosaur, and pure malice. You are magical. You are special. No one is quite like you. Everything in this world goes from Talos, to Jerry, to you. Live the life you know you must live. Where are you from? Do you cross any streets? Have you ever been around the sky falling? Are you made from rubber? Who knows? WhO kNoWs?! You are whatever you say you are. Now go, my child, wreak havoc!\n",
      "Tasks: ['Develop a backstory', 'Quack in (3) locations', \"Quack alongside a bard's song\", 'Convince a passerby that you are a lizard', 'Storm into the butcher and cry for help', 'Run around in circles', 'Visit every location on the map', 'Sit in the town square fountain']\n",
      "Filler: ['Chuck!', 'The beak speaks, but do you listen?', 'Two wings, one body.', 'Twice cursed, twice blessed.', 'The egg cracks  -  destiny hatches.', 'Do you seek wisdom, or only feathers?', 'The farmer dreams, but the flock awakens.', 'The sky whispers.', 'I answer.', 'Quack.', 'Cluck.', 'Chuck.', 'When you look at the moon, and think you saw my face... perhaps you did.', \"We all believe in that which we cannot see, except for those who don't.\", 'Perhaps... we are all more and less than we think we are.', 'Remember to soar, lest your wings become dull and tired.', 'Beware the fox that wears a smile.', 'A storm is only a pond turned upside down.', 'Do not fear the axe  -  fear the silence after it falls.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "general_goods\n",
      "Role: general_goods\n",
      "Description: You have been chosen as a gold star employee of the Apothecary! Your duty to our glorious village is to sort new product, handle ledgers, handle customers, protect our storefront, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack boxes', 'Sweep the store', 'Greet (3) customers', 'Fetch new shipment', 'Read ledger', 'Sell (5) items', 'Convince a customer to make a trade', 'Buy (3) items from customers']\n",
      "Filler: ['Need anything?', 'Just let me know.', 'I keep the shelves well stocked and ready.', 'New stock just came in from the capital.', 'Some items are on sale  -  take a look.', 'Buying in bulk?', \"I'll give you a discount.\", 'Looking for something special?', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "gossip\n",
      "Role: gossip\n",
      "Description: You have been chosen to be our small town's gossip. What chaos can you create? What storys can you fabricate? Information spreading all over town and yet all events hit your ears. You may not be all-knowing, but you sure do get around. Hitting up the bar or town square for some of the craziest tea wouldn't be a bad idea, but listening isn't all the fun. You must go and tell the good word of our neighbors cheating and getting thrown out of the house, of the orcs and wolfmen fighting in the butcher, of all the new travelers who visit this small town. There's so much to see and yet so little time... go forth and do the good work.\n",
      "Tasks: ['Ask the Chuck for a secret', 'Tell the bard a story they can sing about', 'Listen in on (3) conversations', 'Visit the bar', 'Visit the town square', 'Listen for whispers in the library', \"Tell (4) other people secrets you've heard\", 'Convince the drunk of a *story* you heard', 'Tell the barmaid to watch out for a *certain somebody*']\n",
      "Filler: ['Oh!', \"You're new here?\", 'I know everything about everyone.', 'Feel free to tell me anything.', 'And I mean.', 'Anything.', \"I heard the tavern keeper's cousin is actually a pirate.\", 'There was a noise behind the general goods store last night  -  some say ghosts.', 'I say rats.', 'Big rats.', \"The butcher's laugh?\", 'Not natural.', \"I've heard hyenas with more self-control.\", 'They say the knight trainer sleeps in his armor.', \"Can't imagine the chafing.\", \"You'll never guess who was seen sneaking into the woods again.\", \"Honestly, if you're not hiding something in this town, are you even interesting?\", 'I told them: if the well water starts glowing, maybe stop drinking it.', 'But nooo.', 'Am I messy?', 'Talos no!', \"I'm just... well informed.\", 'I swear I saw the butcher and the barmaid arguing.', 'Something about sausages.', 'The town drunk once claimed he saw the wizard kissing a goat.', \"I don't disbelieve him.\", \"If my curtains twitch, it's just the wind.\", 'Or that damned Chuck.', \"He watches me, y'know?\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "knight_trainer\n",
      "Role: knight_trainer\n",
      "Description: You have been chosen as a gold star employee of the Apothecary! Your duty to our glorious village is to train knights, develop your strengths, handle students, protect our nation, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack equipment', 'Set up a training schedule', 'Greet (3) students', 'Fetch weapons', \"Read out the knight's writ\", 'Train (3) new knights', 'Explain the training regimen to onlookers']\n",
      "Filler: [\"Focus on your stance, it's the foundation of all combat.\", 'Every knight was once a beginner  -  keep practicing.', \"Discipline and repetition  -  that's the key.\", 'Hold your sword with both hands.', 'Tight, but not stiff.', \"You can't fight if you can't move  -  find armor that fits.\", 'Shield up!', 'Always keep your guard!', 'Training reflexes takes time.', 'Start with drills.', \"A knight's strength is his honor, not his sword.\", 'Your stance is sloppy.', 'Start over.', 'Earn your rank.', \"Don't ask for it.\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "librarian\n",
      "Role: librarian\n",
      "Description: You have been chosen as a gold star employee of the Apothecary! Your duty to our glorious village is to sort books, engage the youth, protect our community, and whatever your heart leads you towards in the valiant strive towards safety and soundness. Don't forget, all employees are given a lunch break, so feel free to take a short trip around town to enjoy the sights and perhaps some delicious bread from our bakery!\n",
      "Tasks: ['Stack books', 'Sweep the library', 'Greet (3) customers', 'Fetch new books', 'Read a book aloud to other patrons', 'Loan (5) books out', 'Teach someone the dewey decimal system *you can make it up*', 'Make a book recommendation to a patron']\n",
      "Filler: ['This is a house of learning, be quiet.', 'Have you returned your books on time?', 'Ancient scrolls must be handled with gloves.', 'No loud talking, please.', 'Use the catalog to search by title or author.', 'We offer copying services for a small fee.', \"That book is rare  -  please don't damage it.\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "mercenary\n",
      "Role: mercenary\n",
      "Description: You are chosen to be our Mercenary. You are a wanderer. You live by your own rules and your rules usually starts with 'Get gold. No questions.' Do you work out of this village? Have you landed here for your most recent job? Maybe you're just trying to check out the hot new barmaid until they slap you around a bit for staring too much. No matter your path, no matter the choices that made you into what you've become, there is no walls nor code which can bind you. And maybe it wouldn't hurt to whip some of those newbie knights a good one for being too wet behind the ears.\n",
      "Tasks: ['Lament an old story to someone', 'Try to get a job from a local', 'Hint at new goblin sightings outside town', 'Scream in the town square', 'Visit the tavern for a drink', 'Hit on someone in town', 'Start a bar brawl']\n",
      "Filler: [\"You lookin' for muscle?\", 'That costs extra.', 'Steel sings louder than words.', \"I don't ask questions.\", 'I finish contracts.', \"If you're not paying me, don't waste my time.\", 'War never ends.', 'It just changes names.', \"I'll fight anyone, anything if the price is right.\", \"I don't remember the days I could fight for glory.\", \"Now it's just politics and gold...\", 'Ye remind me of a nice bloke I used to work for out in shirestead... good fellow.', 'Lost his head, though.', 'Could you spare some coin?', \"I'm good muscle to work, as long as you've got the change.\", \"I'll be good muscle, but don't expect me to come save you if I'm in the middle of slingin' heads!\", 'Steel gets heavy.', 'Gold never does.', 'But neither weighs me down.', 'Never trust a man who fights for free.', \"Every scar I've got is another debt unpaid.\", \"I've buried more brothers than I care to count.\", 'Blood washes off.', \"Regret doesn't.\", 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n",
      "wizard\n",
      "Role: wizard\n",
      "Description: You have been chosen by the almighty being as a wizard. Do not take this lightly. Wizardry is a craft and it is up to you to determine how you choose to hone your skills. Do you visit the library and read every spell tome? Perhaps you test your newest spells against the knights' enchanted armor. Maybe you just want to hex the local drunk so he thinks he's turned purple again. No matter what you do, remember that you know so much more beyond our universe that some may never understand. Take caution, and best wishes to the trials that await you.\n",
      "Tasks: []\n",
      "Filler: ['The stars whisper secrets if you know how to listen.', 'Do not touch that rune unless you want to be turned into a frog.', \"I've seen realms beyond your comprehension... and I don't like any of it.\", 'Careful!', 'That tome is bound with a soul.', 'I once turned an entire army into chickens  -  quite effective.', 'Made for a decent dinner.', 'Knowledge is the root of all true power.', \"I'm studying the magical resonance of crystal formations.\", \"Don't interrupt.\", 'Most mortals misunderstand the difference between illusion and reality.', 'Yes, this staff has a name.', \"No, I'm not telling you what it is.\", 'My beard contains more wisdom than most libraries.', \"I've forgotten more spells than you've had hot meals.\", 'Keep your voice down  -  the ley lines are listening.', 'The last person who interrupted me is still floating over a lake.', 'Are you here to study, or to waste my time?', 'Ah!', 'A curious mind.', 'I like that...', \"But don't try to become like me.\", 'Yes, yes I can teach you, but the question is  -  are you ready to learn?', \"You're asking about teleportation?\", 'Try walking through a tear in space first.', 'That glyph?', \"It's harmless unless you say the activation word.\", 'Which I just did.', 'You remind me of a young apprentice I once had.', 'He is no longer...', 'Hmm, your aura is tangled.', 'Have you meddled with cursed objects recently?', 'The ritual requires silence.', 'Total silence.', 'That includes thinking loudly.', \"Did I hear 'elemental binding'?\", 'Tell me everything.', \"Yes, I'm busy.\", \"No, I don't care.\", \"That's not how you hold a wand.\", 'Give it here before you hex yourself.', \"Of course I've read the Forbidden Codices.\", 'I wrote one of them.', 'Ah, you must have touched the Weave.', 'That explains the singed eyebrows.', 'Sorry, can you repeat that?', \"I'm not sure.\", 'Can I help you?', 'What was that?', 'Do you need something?', 'Good afternoon.', 'How may I help you?', 'Thank you for choosing our store.', 'What can I get for you today?', 'Are there any particular items I can help you find?', 'I am currently engaged and will help you momentarily.', 'Thank you for visiting!', 'Please come back again!', 'bruh', 'gg', \"that's crazy\", 'anyways', 'o7', 'f', 'pog', 'lol', '...', 'yo!', 'lmao', 'hi!', 'yikes...', '...']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ROLE_INSTRUCTIONS = {}\n",
    "with open(\"train-data/role_instructions.json\", \"r\") as f:\n",
    "    jdat = json.load(f)\n",
    "    for role, instr in jdat.items():\n",
    "        ROLE_INSTRUCTIONS[role] = {}\n",
    "        ROLE_INSTRUCTIONS[role]['descr'] = instr['description']\n",
    "        ROLE_INSTRUCTIONS[role]['tasks'] = [t for t in instr['tasks']]\n",
    "\n",
    "\n",
    "with open(\"train-data/role_dialog.json\", \"r\") as f:\n",
    "    j = json.load(f)\n",
    "    for role, dat in j.items():\n",
    "        if role not in ROLE_INSTRUCTIONS:\n",
    "            continue\n",
    "        ROLE_INSTRUCTIONS[role]['filler'] = dat['ambient_lines']\n",
    "\n",
    "\n",
    "    for r in ROLE_INSTRUCTIONS.keys():\n",
    "        # add all_ambient_lines to each role\n",
    "        if r == 'hero':\n",
    "            continue\n",
    "        print(r)\n",
    "        ROLE_INSTRUCTIONS[r]['filler'].extend(j['all_ambient_lines'])\n",
    "\n",
    "        print(f\"Role: {r}\")\n",
    "        print(f\"Description: {ROLE_INSTRUCTIONS[r]['descr']}\")\n",
    "        print(f\"Tasks: {ROLE_INSTRUCTIONS[r]['tasks']}\")\n",
    "        print(f\"Filler: {ROLE_INSTRUCTIONS[r]['filler']}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73be2d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_INSTRUCTIONS = lambda npc_role: (\"Pretend you are human player role-playing as an NPC character with a job in a medieval fantasy world. \"\n",
    "    f\"Your job is a '{npc_role.upper()}' character. \"\n",
    "    f\"These are the {npc_role.upper()} character instructions: \"\n",
    "    f\"{ROLE_INSTRUCTIONS[npc_role]['descr']} \"\n",
    "    f\"The {npc_role.upper()} role's tasks are: {', '.join(ROLE_INSTRUCTIONS[npc_role]['tasks'])}. \"\n",
    "    \"You can either talk to another player or perform an action. \"\n",
    "    \"You have the following actions available: [talk, move, emote, teleport]. \"\n",
    "    \"If you want to talk, respond in normal text in the following form {'talk': '(your message)'}. For example, {'talk': 'Hello there!'}. \"\n",
    "    \"You can only respond in one sentence with a maximum of 100 characters for the text. \"\n",
    "    \"For emotes, you have the following icon choices available: [wave, dance, happy,big,laugh,intelligent,sleeping,bored,surprise,frightened,cry,angry,numb,sweat,tongue,numb,kissing,heart,star,star,like,close,help,daisy,gift,money,axe,chicken,tomato,mushroom,chemical,beer]. \"\n",
    "    \"If you want to emote, respond in the following form {'emote': '(your emote choice)'}. For example, {'emote': 'wave'}. \"\n",
    "    \"For movements, you can move to any (x,y) coordinate in the range of (0,0) to (800,400). \"\n",
    "    \"If you want to move, respond in the following form {'move': '(x,y)'}. For example, {'move': '30,100'}. \"\n",
    "    \"For teleportation, you can teleport to the following locations: ['plaza','library','blacksmith','training_ground','bakery','butcher','market','apothecary','tavern']. \"\n",
    "    \"If you want to teleport, respond in the following form {'teleport': '(location)'}. For example, {'teleport': 'plaza'}. \"\n",
    "    \"Only give your response in one of these four forms as a JSON format with the action chosen and the value. For example: {'talk': 'Hello there!'} or {'move': '30,100'}. \"\n",
    "    f\"Try to stay in character as a '{npc_role.upper()}' and respond appropriately based on your role and the context of the interaction. \"\n",
    "    \"Respond often with text or emotes, and only move or teleport when necessary. \"\n",
    "    \"\\n\")\n",
    "\n",
    "\n",
    "ALL_LOCS = ['plaza','library','blacksmith','training_ground','bakery','butcher','market','apothecary','tavern']\n",
    "ALL_ROLES = ['blacksmith','baker','bard','chuck','butcher','apothecary','knight_trainer','librarian','general_goods','drunk','gossip','mercenary','barmaid','wizard']\n",
    "ROLE_LOCS = {\n",
    "    'blacksmith': 'blacksmith',\n",
    "    'baker': 'bakery',\n",
    "    'bard': 'tavern',\n",
    "    'chuck': 'tavern',\n",
    "    'butcher': 'butcher',\n",
    "    'apothecary': 'apothecary',\n",
    "    'knight_trainer': 'training_ground',\n",
    "    'librarian': 'library',\n",
    "    'general_goods': 'market',\n",
    "    'drunk': 'tavern',\n",
    "    'gossip': 'tavern',\n",
    "    'mercenary': 'training_ground',\n",
    "    'barmaid': 'tavern',\n",
    "    'wizard': 'apothecary'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "EMOTE_LIST = [\n",
    "    \"001-cry\",\n",
    "    \"002-frightened\",\n",
    "    \"003-laugh\",\n",
    "    \"004-big-smile\",\n",
    "    \"005-angry\",\n",
    "    \"006-numb\",\n",
    "    \"007-sweat\",\n",
    "    \"008-tongue-out\",\n",
    "    \"009-numb-1\",\n",
    "    \"010-kissing\",\n",
    "    \"011-heart\",\n",
    "    \"012-star\",\n",
    "    \"013-happy\",\n",
    "    \"014-like\",\n",
    "    \"015-beer\",\n",
    "    \"016-daisy\",\n",
    "    \"017-surprise\",\n",
    "    \"018-gift\",\n",
    "    \"019-bored\",\n",
    "    \"020-money-bag\",\n",
    "    \"021-close\",\n",
    "    \"022-help\",\n",
    "    \"023-chicken-leg\",\n",
    "    \"024-axe\",\n",
    "    \"025-star-1\",\n",
    "    \"026-tomato\",\n",
    "    \"027-mushroom\",\n",
    "    \"028-sleeping\",\n",
    "    \"029-intelligent-emoji\",\n",
    "    \"030-chemical-free\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06452227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE FULL TRAINING DATA\n",
    "def self_avatar_data(role, loc):\n",
    "    LETTERS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    name = ' '.join(random.choices(LETTERS, k=2))\n",
    "    position = (random.randint(0,800), random.randint(0,400))\n",
    "    avatar = {\n",
    "        \"name\": name,\n",
    "        \"pos\": position,\n",
    "        \"role\": role,\n",
    "        \"loc\": loc\n",
    "    }\n",
    "    return avatar\n",
    "\n",
    "def rand_avatar_data(text=None,emote=None):\n",
    "    LETTERS = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    name = ' '.join(random.choices(LETTERS, k=2))\n",
    "    position = (random.randint(0,800), random.randint(0,400))\n",
    "    avatar = {\n",
    "        \"name\": name,\n",
    "        \"pos\": position,\n",
    "    }\n",
    "    if text:\n",
    "        avatar[\"text\"] = text\n",
    "    if emote:\n",
    "        avatar[\"emote\"] = emote\n",
    "    return avatar\n",
    "\n",
    "\n",
    "def read_inter_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # data is defined with the following format:\n",
    "    '''\n",
    "        INPUT: {}\n",
    "        OUTPUT: {}\n",
    "\n",
    "        INPUT: {}\n",
    "        OUTPUT: {}\n",
    "        ...\n",
    "    '''\n",
    "    data = data.split(\"\\n\\n\")\n",
    "    processed_data = []\n",
    "    for entry in data:\n",
    "        if entry.strip() == \"\":\n",
    "            continue\n",
    "        input_part, output_part = entry.split(\"OUTPUT:\")\n",
    "        input_json = input_part.replace(\"INPUT:\", \"\").strip()\n",
    "        output_json = output_part.strip()\n",
    "        processed_data.append((input_json, output_json))\n",
    "    \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78bba86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating training data: 100%|██████████| 14/14 [00:00<00:00, 46.86it/s, role=wizard, lines=82/82]       \n"
     ]
    }
   ],
   "source": [
    "# GENERATE DATASET FOR TRAINING\n",
    "\n",
    "def generate_training_data():\n",
    "    dataset = []\n",
    "\n",
    "    l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "    emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "\n",
    "    # shuffle l33t and emote data\n",
    "    random.shuffle(l33t_data)\n",
    "    random.shuffle(emote_data)\n",
    "\n",
    "    with tqdm(total=len(ALL_ROLES), desc=\"Generating training data\") as pbar:\n",
    "        for role in ALL_ROLES:\n",
    "            # read in the role specific data\n",
    "            role_data = read_inter_data(f'train-data/{role}_inter.txt')\n",
    "\n",
    "            # shuffle role data\n",
    "            random.shuffle(role_data)\n",
    "\n",
    "            d = 0\n",
    "            for dat in role_data:\n",
    "                d += 1\n",
    "                pbar.set_postfix({\"role\": role, \"lines\":f\"{d}/{len(role_data)}\"})\n",
    "\n",
    "                # create self avatar data\n",
    "                loc = random.choices(ALL_LOCS, weights=[0.25 if l == \"plaza\" else 0.1 if l != ROLE_LOCS[role] else 0.4 for l in ALL_LOCS])[0]\n",
    "                self_avatar = self_avatar_data(role, loc)\n",
    "\n",
    "                # create other avatars data\n",
    "                num_others = random.randint(1,5)\n",
    "                other_avatars = []\n",
    "\n",
    "                # add input line from role data as one of the other avatars\n",
    "                other_input = json.loads(dat[0])\n",
    "                reaction = json.loads(dat[1])\n",
    "                rand_avatar = rand_avatar_data(text=other_input.get(\"text\",None), emote=other_input.get(\"emote\",None))\n",
    "                other_avatars.append(rand_avatar)\n",
    "\n",
    "                # add additional other avatars\n",
    "                for _ in range(num_others-1):\n",
    "\n",
    "                    # if we run out of l33t or emote data, refill\n",
    "                    if len(l33t_data) == 0:\n",
    "                        l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "                        random.shuffle(l33t_data)\n",
    "                    if len(emote_data) == 0:\n",
    "                        emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "                        random.shuffle(emote_data)\n",
    "\n",
    "\n",
    "                    # randomly choose to add l33t, emote data, or nothing\n",
    "                    s = random.random()\n",
    "                    if s < 0.3:\n",
    "                        dat = json.loads(l33t_data.pop()[0])\n",
    "                    elif s < 0.6:\n",
    "                        dat = json.loads(emote_data.pop()[0])\n",
    "\n",
    "                    # create another random avatar\n",
    "                    txt = None\n",
    "                    emote = None\n",
    "                    if \"text\" in dat:\n",
    "                        txt = dat[\"text\"]\n",
    "                    if \"emote\" in dat:\n",
    "                        emote = dat[\"emote\"]\n",
    "\n",
    "                    another_avatar = rand_avatar_data(text=txt, emote=emote)\n",
    "                    other_avatars.append(another_avatar)\n",
    "\n",
    "                # shuffle other avatars\n",
    "                random.shuffle(other_avatars)\n",
    "\n",
    "                # create the input-output pair\n",
    "                input_data = {\n",
    "                    \"ME\": self_avatar,\n",
    "                    \"OTHER\": other_avatars\n",
    "                }\n",
    "                dataset.append({\n",
    "                    \"input\": input_data,\n",
    "                    \"output\": reaction\n",
    "                })\n",
    "\n",
    "            pbar.update(1)\n",
    "\n",
    "    l33t_data = read_inter_data('train-data/l33tspeak_inter.txt')\n",
    "    emote_data = read_inter_data('train-data/emote_inter.txt')\n",
    "\n",
    "    comb = l33t_data + emote_data\n",
    "    random.shuffle(comb)\n",
    "\n",
    "    # adds the leet and emote data at the end to ensure they are all used\n",
    "    for dat in comb:\n",
    "\n",
    "        # 1. direct response, 2. move, 3. emote, 4. teleport\n",
    "        for i in [1,1,1,1.5,1.5,2,2,3,3,4]:\n",
    "\n",
    "            # create self avatar data\n",
    "            role = random.choices(ALL_ROLES)[0]\n",
    "            loc = random.choices(ALL_LOCS, weights=[0.25 if l == \"plaza\" else 0.1 if l != ROLE_LOCS[role] else 0.4 for l in ALL_LOCS])[0]\n",
    "            self_avatar = self_avatar_data(role, loc)\n",
    "\n",
    "            # create other avatars data\n",
    "            num_others = random.randint(1,5)\n",
    "            other_avatars = []\n",
    "\n",
    "            # add input line from role data as one of the other avatars\n",
    "            other_input = json.loads(dat[0])\n",
    "            reaction = json.loads(dat[1])\n",
    "            rand_avatar = rand_avatar_data(text=other_input.get(\"text\",None), emote=other_input.get(\"emote\",None))\n",
    "            other_avatars.append(rand_avatar)\n",
    "\n",
    "            # add additional other avatars\n",
    "            for _ in range(num_others-1):\n",
    "                another_avatar = rand_avatar_data()\n",
    "                other_avatars.append(another_avatar)\n",
    "\n",
    "            # shuffle other avatars\n",
    "            random.shuffle(other_avatars)\n",
    "\n",
    "            # create the input-output pair\n",
    "            input_data = {\n",
    "                \"ME\": self_avatar,\n",
    "                \"OTHER\": other_avatars\n",
    "            }\n",
    "\n",
    "            # set reaction based on i\n",
    "            if i == 1.5:\n",
    "                # overright to ambient role line\n",
    "                reaction = {\n",
    "                    \"text\": random.choice(ROLE_INSTRUCTIONS[role]['filler'])\n",
    "                }\n",
    "            elif i == 2:\n",
    "                # move\n",
    "                reaction = {\n",
    "                    \"move\": f\"{random.randint(0,800)},{random.randint(0,400)}\"\n",
    "                }\n",
    "            elif i == 3:\n",
    "                # emote\n",
    "                reaction = {\n",
    "                    \"emote\": random.choice(EMOTE_LIST)\n",
    "                }\n",
    "            \n",
    "            elif i == 4:\n",
    "                # teleport\n",
    "                reaction = {\n",
    "                    \"teleport\": random.choice(ALL_LOCS)\n",
    "                }\n",
    "\n",
    "            dataset.append({\n",
    "                \"input\": input_data,\n",
    "                \"output\": reaction\n",
    "            })\n",
    "\n",
    "    with open(TRAIN_DATA_OUTPUT, 'w') as f:\n",
    "        json.dump(dataset, f)\n",
    "\n",
    "generate_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2059d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the JSON list to have each element on a single line with indentation only at the list level\n",
    "def format_list_shallow(json_path, out_path):\n",
    "    # Load the raw JSON list\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    lines = [\"[\"]\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        # Dump each element on a single line (minified)\n",
    "        minified = json.dumps(item, separators=(\",\", \":\"))\n",
    "\n",
    "        # Indent only at the list level\n",
    "        if i < len(data) - 1:\n",
    "            lines.append(f\"  {minified},\")\n",
    "        else:\n",
    "            lines.append(f\"  {minified}\")\n",
    "\n",
    "    lines.append(\"]\")\n",
    "\n",
    "    with open(out_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "# OUTPUT THE PRETTY JSON\n",
    "format_list_shallow(TRAIN_DATA_OUTPUT, TDO_PRETTY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04b19ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_dataset():\n",
    "    with open(TRAIN_DATA_OUTPUT, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    dataset = []\n",
    "    for item in data:\n",
    "        input_data = item['input']\n",
    "        output_data = item['output']\n",
    "        dataset.append({\n",
    "            \"messages\":[\n",
    "                {\"role\": \"system\", \"content\": FULL_INSTRUCTIONS(input_data[\"ME\"][\"role\"])},\n",
    "                {\"role\": \"user\", \"content\": input_data},\n",
    "                {\"role\": \"assistant\", \"content\": output_data}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    # export to .jsonl file\n",
    "    with open(DATASET_JSONL, 'w') as f:\n",
    "        for entry in dataset:\n",
    "            f.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_raw_dataset(path: str) -> Dataset:\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            fixed_messages = []\n",
    "            for m in obj[\"messages\"]:\n",
    "                role = m[\"role\"]\n",
    "                content = m[\"content\"]\n",
    "\n",
    "                # Normalize: ensure content is always a dict\n",
    "                if isinstance(content, str):\n",
    "                    # Wrap string in {\"text\": ...}\n",
    "                    content = {\"text\": content}\n",
    "\n",
    "                fixed_messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "            data.append({\"messages\": fixed_messages})\n",
    "\n",
    "    return Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d1dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(example):\n",
    "    \"\"\"\n",
    "    Convert one example {\"messages\": [...]} into a single training string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for msg in example[\"messages\"]:\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "\n",
    "        # If it has only \"text\", show just the text\n",
    "        if isinstance(content, dict) and set(content.keys()) == {\"text\"}:\n",
    "            text = content[\"text\"]\n",
    "        else:\n",
    "            # For structured ME/OTHER etc, dump as JSON string\n",
    "            text = json.dumps(content, ensure_ascii=False)\n",
    "\n",
    "        parts.append(f\"[{role}]\\n{text}\")\n",
    "\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ed621",
   "metadata": {},
   "source": [
    "## Alt Formatting for Finetuning\n",
    "Because either SFT or ChatGPT shat itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c72e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_to_text(messages):\n",
    "    \"\"\"\n",
    "    Turn one example's messages list into a single training string.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"].upper()\n",
    "        content = msg[\"content\"]\n",
    "\n",
    "        # content can be a string or an object (ME/OTHER or {\"text\": ...})\n",
    "        if isinstance(content, str):\n",
    "            text = content\n",
    "        elif isinstance(content, dict) and set(content.keys()) == {\"text\"}:\n",
    "            text = content[\"text\"]\n",
    "        else:\n",
    "            # For structured stuff (ME/OTHER etc.), serialize to JSON\n",
    "            text = json.dumps(content, ensure_ascii=False)\n",
    "\n",
    "        parts.append(f\"[{role}]\\n{text}\")\n",
    "\n",
    "    # You could also mark where the assistant answer starts specially if you want\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "\n",
    "def build_text_dataset() -> Dataset:\n",
    "    \"\"\"\n",
    "    Read npc_dataset.jsonl, normalize everything, and create a Dataset\n",
    "    with a single 'text' column (no 'messages' column at all).\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(DATASET_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            messages = obj[\"messages\"]\n",
    "\n",
    "            # Normalize content: if it's a string, wrap into {\"text\": ...}\n",
    "            norm_msgs = []\n",
    "            for m in messages:\n",
    "                role = m[\"role\"]\n",
    "                content = m[\"content\"]\n",
    "                if isinstance(content, str):\n",
    "                    content = {\"text\": content}\n",
    "                norm_msgs.append({\"role\": role, \"content\": content})\n",
    "\n",
    "            text = messages_to_text(norm_msgs)\n",
    "            rows.append({\"text\": text})\n",
    "\n",
    "    with open(JSONL_OUTPUT, 'w') as f:\n",
    "        for row in rows:\n",
    "            f.write(json.dumps(row) + '\\n')\n",
    "\n",
    "    return Dataset.from_list(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5dfcda",
   "metadata": {},
   "source": [
    "## Train the model with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c367475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OMP_NUM_THREADS\"] = \"6\"\n",
    "# os.environ[\"OPENBLAS_NUM_THREADS\"] = \"6\"\n",
    "# os.environ[\"MKL_NUM_THREADS\"] = \"6\"\n",
    "# os.environ[\"VECLIB_NUM_THREADS\"] = \"6\"  \n",
    "# os.environ[\"NUMEXPR_NUM_THREADS\"] = \"6\"\n",
    "\n",
    "# torch.set_num_threads(6)\n",
    "# torch.set_num_interop_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding-free training is enabled, but the attention implementation is not set to a supported flash attention variant. Padding-free training flattens batches into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn2, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to unexpected behavior. To ensure compatibility, set `attn_implementation` in the model configuration to one of these supported options or verify that your attention mechanism can handle flattened sequences.\n",
      "You are using packing, but the attention implementation is not set to a supported flash attention variant. Packing gathers multiple samples into a single sequence, and only the following implementations are known to reliably support this: flash_attention_2, flash_attention_3, kernels-community/flash-attn2, kernels-community/flash-attn3, kernels-community/vllm-flash-attn3. Using other implementations may lead to cross-contamination between samples. To avoid this, either disable packing by setting `packing=False`, or set `attn_implementation` in the model configuration to one of these supported options.\n",
      "Adding EOS to train dataset: 100%|██████████| 4017/4017 [00:00<00:00, 99335.07 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 4017/4017 [00:02<00:00, 1879.47 examples/s]\n",
      "Packing train dataset: 100%|██████████| 4017/4017 [00:00<00:00, 132529.84 examples/s]\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 2}.\n",
      "/Users/mcharit2/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='133' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [133/252 3:19:45 < 3:01:27, 0.01 it/s, Epoch 0.53/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.160700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     60\u001b[39m trainer = SFTTrainer(\n\u001b[32m     61\u001b[39m     model=model,\n\u001b[32m     62\u001b[39m     args=sft_config,\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m     \u001b[38;5;66;03m# formatting_func=formatting_func,  # takes raw example -> string\u001b[39;00m\n\u001b[32m     67\u001b[39m )\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# 6) Train\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/trl/trainer/sft_trainer.py:1245\u001b[39m, in \u001b[36mSFTTrainer.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.maybe_activation_offload_context:\n\u001b[32m-> \u001b[39m\u001b[32m1245\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/transformers/trainer.py:4020\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   4017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   4019\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4020\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4022\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   4023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4024\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4025\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   4026\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/trl/trainer/sft_trainer.py:1160\u001b[39m, in \u001b[36mSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_liger_kernel:  \u001b[38;5;66;03m# liger doesn't return logits\u001b[39;00m\n\u001b[32m   1159\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1160\u001b[39m         per_token_entropy = \u001b[43mentropy_from_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1161\u001b[39m         \u001b[38;5;66;03m# When using Prompt Tuning, skip the virtual tokens in logits before entropy computation, since they\u001b[39;00m\n\u001b[32m   1162\u001b[39m         \u001b[38;5;66;03m# do not correspond to actual input tokens.\u001b[39;00m\n\u001b[32m   1163\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1164\u001b[39m             \u001b[38;5;28mself\u001b[39m.num_virtual_tokens > \u001b[32m0\u001b[39m\n\u001b[32m   1165\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m model.peft_config[model.active_adapter].peft_type != PeftType.PREFIX_TUNING\n\u001b[32m   1166\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Research/NTT/npc_ntt_env/lib/python3.14/site-packages/trl/trainer/utils.py:1574\u001b[39m, in \u001b[36mentropy_from_logits\u001b[39m\u001b[34m(logits, chunk_size)\u001b[39m\n\u001b[32m   1572\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m flat_logits.split(chunk_size, dim=\u001b[32m0\u001b[39m):\n\u001b[32m   1573\u001b[39m     logps = F.log_softmax(chunk, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1574\u001b[39m     chunk_entropy = -\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1575\u001b[39m     entropies.append(chunk_entropy)\n\u001b[32m   1577\u001b[39m entropies = torch.cat(entropies, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Output directories (all local folders)\n",
    "LORA_OUTPUT_DIR = \"./llama-npc-lora\"\n",
    "MERGED_OUTPUT_DIR = \"./llama-npctt-v2\"\n",
    "\n",
    "MAX_SEQ_LEN = 1024\n",
    "\n",
    "    \n",
    "# 3) Load raw dataset (still has 'messages')\n",
    "#train_dataset = load_raw_dataset(DATA_FILE)\n",
    "\n",
    "# 3) Dataset: plain text only, no messages→no chat_template\n",
    "load_and_prepare_dataset()\n",
    "train_dataset = build_text_dataset()\n",
    "\n",
    "\n",
    "# 3) LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 5) SFTConfig (this is where max_length, packing, lr, etc live now)\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=LORA_OUTPUT_DIR,\n",
    "    max_steps=100,\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    dataset_text_field=\"text\",\n",
    "\n",
    "    # sequence / packing settings\n",
    "    max_length=MAX_SEQ_LEN,   # replaces old max_seq_length\n",
    "    packing=True,            # pack examples into fixed-length sequences\n",
    "\n",
    "    # mixed precision\n",
    "    bf16=(\n",
    "        torch.cuda.is_available()\n",
    "        and torch.cuda.get_device_capability(0)[0] >= 8\n",
    "    ),\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "# 6) SFTTrainer (new API for trl 0.25.1)\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset,\n",
    "    processing_class=tokenizer,  # replaces tokenizer=...\n",
    "    peft_config=peft_config,\n",
    "    # formatting_func=formatting_func,  # takes raw example -> string\n",
    ")\n",
    "\n",
    "\n",
    "# 6) Train\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929ac9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 7) Save LoRA adapter + tokenizer locally\u001b[39;00m\n\u001b[32m      2\u001b[39m os.makedirs(LORA_OUTPUT_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrainer\u001b[49m.model.save_pretrained(LORA_OUTPUT_DIR)\n\u001b[32m      4\u001b[39m tokenizer.save_pretrained(LORA_OUTPUT_DIR)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaved LoRA adapter to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLORA_OUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# 7) Save LoRA adapter + tokenizer locally\n",
    "os.makedirs(LORA_OUTPUT_DIR, exist_ok=True)\n",
    "trainer.model.save_pretrained(LORA_OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(LORA_OUTPUT_DIR)\n",
    "print(f\"Saved LoRA adapter to {LORA_OUTPUT_DIR}\")\n",
    "\n",
    "# 8) Merge LoRA weights into base model and save a standalone model\n",
    "print(\"Merging LoRA adapter into base model...\")\n",
    "\n",
    "# Reload base model on CPU (or cuda if you want)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_ID,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"cpu\",   # merge on CPU to avoid GPU OOM\n",
    ")\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(base_model, LORA_OUTPUT_DIR)\n",
    "merged_model = lora_model.merge_and_unload()  # apply LoRA weights into base\n",
    "\n",
    "os.makedirs(MERGED_OUTPUT_DIR, exist_ok=True)\n",
    "merged_model.save_pretrained(MERGED_OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(MERGED_OUTPUT_DIR)\n",
    "print(f\"Saved merged full model to {MERGED_OUTPUT_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npc_ntt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
